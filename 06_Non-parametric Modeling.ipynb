{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be one last attempt at trying to create a model for this dataset. As I've already explained, there is still quite a bit of information missing for a comprehensive model, but I'm going to attempt to use a non-parametric algorithm. Up until this point, I had just been using different iterations of a linear regression model, which the data has proved does not fit that trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTBS Data\n",
    "mtbs = pd.read_csv('MTBS_clean.csv')\n",
    "mtbs.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "#Ecoregion Level 3 - Weather Data\n",
    "weather = pd.read_csv('Ecoregion Level 3 Weather.csv', skiprows=[1])\n",
    "weather.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to date\n",
    "weather['Date'] = pd.to_datetime(weather['Date'], format='%Y-%m-%d')\n",
    "mtbs['Date'] = pd.to_datetime(mtbs['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Data\n",
    "mtbs_weather_3 = pd.merge(mtbs, weather, how='left', on=['NA_L3NAME', 'Date'])\n",
    "mtbs_weather_3.drop(columns=['wind_speed_ms_30', 'wind_speed_ms_90', 'wind_speed_ms_180', 'wind_speed_ms_365'],\n",
    "                   inplace=True)\n",
    "mtbs_weather_3.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_keep = ['Fire_Type', 'Low_T', 'Mod_T', 'High_T', 'NA_L3NAME', 'state', 'month_ig', 'max_temp_C_90',\n",
    "           'precipitation_cm_90', 'Acres']\n",
    "\n",
    "df_model_1 = mtbs_weather_3[col_keep]\n",
    "df_model_1 = df_model_1[df_model_1['Fire_Type'] == 'Wildfire']\n",
    "target_1 = np.array(df_model_1['Acres'])\n",
    "predictors_1 = df_model_1.drop(columns=['Acres'])\n",
    "predictors_1 = pd.get_dummies(predictors_1, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors_1, target_1, test_size=0.2)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8549118000962644"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 10866.49 acres.\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'acres.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: precipitation_cm_90  Importance: 0.19\n",
      "Variable: max_temp_C_90        Importance: 0.17\n",
      "Variable: Low_T                Importance: 0.15\n",
      "Variable: Mod_T                Importance: 0.15\n",
      "Variable: High_T               Importance: 0.12\n",
      "Variable: month_ig             Importance: 0.04\n",
      "Variable: state_OK             Importance: 0.02\n",
      "Variable: state_OR             Importance: 0.02\n",
      "Variable: NA_L3NAME_Arizona/New Mexico Mountains Importance: 0.01\n",
      "Variable: NA_L3NAME_Idaho Batholith Importance: 0.01\n",
      "Variable: NA_L3NAME_Northern Basin and Range Importance: 0.01\n",
      "Variable: NA_L3NAME_Southwestern Tablelands Importance: 0.01\n",
      "Variable: state_AZ             Importance: 0.01\n",
      "Variable: state_ID             Importance: 0.01\n",
      "Variable: state_NV             Importance: 0.01\n",
      "Variable: state_TX             Importance: 0.01\n",
      "Variable: NA_L3NAME_Arizona/New Mexico Plateau Importance: 0.0\n",
      "Variable: NA_L3NAME_Arkansas Valley Importance: 0.0\n",
      "Variable: NA_L3NAME_Aspen Parkland/Northern Glaciated Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Atlantic Coastal Pine Barrens Importance: 0.0\n",
      "Variable: NA_L3NAME_Blue Mountains Importance: 0.0\n",
      "Variable: NA_L3NAME_Blue Ridge Importance: 0.0\n",
      "Variable: NA_L3NAME_California Coastal Sage, Chaparral, and Oak Woodlands Importance: 0.0\n",
      "Variable: NA_L3NAME_Cascades   Importance: 0.0\n",
      "Variable: NA_L3NAME_Central Appalachians Importance: 0.0\n",
      "Variable: NA_L3NAME_Central Basin and Range Importance: 0.0\n",
      "Variable: NA_L3NAME_Central California Valley Importance: 0.0\n",
      "Variable: NA_L3NAME_Central Great Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Central Irregular Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Chihuahuan Desert Importance: 0.0\n",
      "Variable: NA_L3NAME_Chihuahuan Deserts Importance: 0.0\n",
      "Variable: NA_L3NAME_Coast Range Importance: 0.0\n",
      "Variable: NA_L3NAME_Colorado Plateaus Importance: 0.0\n",
      "Variable: NA_L3NAME_Columbia Mountains/Northern Rockies Importance: 0.0\n",
      "Variable: NA_L3NAME_Columbia Plateau Importance: 0.0\n",
      "Variable: NA_L3NAME_Cross Timbers Importance: 0.0\n",
      "Variable: NA_L3NAME_Driftless Area Importance: 0.0\n",
      "Variable: NA_L3NAME_East Central Texas Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Eastern Cascades Slopes and Foothills Importance: 0.0\n",
      "Variable: NA_L3NAME_Eastern Corn Belt Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Eastern Great Lakes Lowlands Importance: 0.0\n",
      "Variable: NA_L3NAME_Edwards Plateau Importance: 0.0\n",
      "Variable: NA_L3NAME_Flint Hills Importance: 0.0\n",
      "Variable: NA_L3NAME_High Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Interior Plateau Importance: 0.0\n",
      "Variable: NA_L3NAME_Interior River Valleys and Hills Importance: 0.0\n",
      "Variable: NA_L3NAME_Klamath Mountains Importance: 0.0\n",
      "Variable: NA_L3NAME_Lake Manitoba and Lake Agassiz Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Madrean Archipelago Importance: 0.0\n",
      "Variable: NA_L3NAME_Middle Atlantic Coastal Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Middle Rockies Importance: 0.0\n",
      "Variable: NA_L3NAME_Mississippi Alluvial Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Mississippi Valley Loess Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Mojave Basin and Range Importance: 0.0\n",
      "Variable: NA_L3NAME_Nebraska Sand Hills Importance: 0.0\n",
      "Variable: NA_L3NAME_North Cascades Importance: 0.0\n",
      "Variable: NA_L3NAME_North Central Appalachians Importance: 0.0\n",
      "Variable: NA_L3NAME_North Central Hardwood Forests Importance: 0.0\n",
      "Variable: NA_L3NAME_Northeastern Coastal Zone Importance: 0.0\n",
      "Variable: NA_L3NAME_Northern Allegheny Plateau Importance: 0.0\n",
      "Variable: NA_L3NAME_Northern Appalachian and Atlantic Maritime Highlands Importance: 0.0\n",
      "Variable: NA_L3NAME_Northern Lakes and Forests Importance: 0.0\n",
      "Variable: NA_L3NAME_Northern Minnesota Wetlands Importance: 0.0\n",
      "Variable: NA_L3NAME_Northern Piedmont Importance: 0.0\n",
      "Variable: NA_L3NAME_Northwestern Glaciated Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Northwestern Great Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Ouachita Mountains Importance: 0.0\n",
      "Variable: NA_L3NAME_Ozark Highlands Importance: 0.0\n",
      "Variable: NA_L3NAME_Piedmont   Importance: 0.0\n",
      "Variable: NA_L3NAME_Ridge and Valley Importance: 0.0\n",
      "Variable: NA_L3NAME_Sierra Nevada Importance: 0.0\n",
      "Variable: NA_L3NAME_Snake River Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Sonoran Desert Importance: 0.0\n",
      "Variable: NA_L3NAME_South Central Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Southeastern Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Southeastern Wisconsin Till Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Southern Coastal Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Southern Florida Coastal Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Southern Michigan/Northern Indiana Drift Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Southern Rockies Importance: 0.0\n",
      "Variable: NA_L3NAME_Southern Texas Plains/Interior Plains and Hills with Xerophytic Shrub and Oak Forest Importance: 0.0\n",
      "Variable: NA_L3NAME_Southern and Baja California Pine-Oak Mountains Importance: 0.0\n",
      "Variable: NA_L3NAME_Southwestern Appalachians Importance: 0.0\n",
      "Variable: NA_L3NAME_Texas Blackland Prairies Importance: 0.0\n",
      "Variable: NA_L3NAME_Wasatch and Uinta Mountains Importance: 0.0\n",
      "Variable: NA_L3NAME_Western Allegheny Plateau Importance: 0.0\n",
      "Variable: NA_L3NAME_Western Corn Belt Plains Importance: 0.0\n",
      "Variable: NA_L3NAME_Western Gulf Coastal Plain Importance: 0.0\n",
      "Variable: NA_L3NAME_Willamette Valley Importance: 0.0\n",
      "Variable: NA_L3NAME_Wyoming Basin Importance: 0.0\n",
      "Variable: state_AR             Importance: 0.0\n",
      "Variable: state_CA             Importance: 0.0\n",
      "Variable: state_CO             Importance: 0.0\n",
      "Variable: state_DE             Importance: 0.0\n",
      "Variable: state_FL             Importance: 0.0\n",
      "Variable: state_GA             Importance: 0.0\n",
      "Variable: state_IA             Importance: 0.0\n",
      "Variable: state_IN             Importance: 0.0\n",
      "Variable: state_KS             Importance: 0.0\n",
      "Variable: state_KY             Importance: 0.0\n",
      "Variable: state_LA             Importance: 0.0\n",
      "Variable: state_MA             Importance: 0.0\n",
      "Variable: state_MD             Importance: 0.0\n",
      "Variable: state_ME             Importance: 0.0\n",
      "Variable: state_MI             Importance: 0.0\n",
      "Variable: state_MN             Importance: 0.0\n",
      "Variable: state_MO             Importance: 0.0\n",
      "Variable: state_MS             Importance: 0.0\n",
      "Variable: state_MT             Importance: 0.0\n",
      "Variable: state_NC             Importance: 0.0\n",
      "Variable: state_ND             Importance: 0.0\n",
      "Variable: state_NE             Importance: 0.0\n",
      "Variable: state_NJ             Importance: 0.0\n",
      "Variable: state_NM             Importance: 0.0\n",
      "Variable: state_NY             Importance: 0.0\n",
      "Variable: state_OH             Importance: 0.0\n",
      "Variable: state_PA             Importance: 0.0\n",
      "Variable: state_SC             Importance: 0.0\n",
      "Variable: state_SD             Importance: 0.0\n",
      "Variable: state_TN             Importance: 0.0\n",
      "Variable: state_UT             Importance: 0.0\n",
      "Variable: state_VA             Importance: 0.0\n",
      "Variable: state_WA             Importance: 0.0\n",
      "Variable: state_WI             Importance: 0.0\n",
      "Variable: state_WV             Importance: 0.0\n",
      "Variable: state_WY             Importance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train.columns, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the Random Forest Regressor was a mixed bag. The r-squared value from the RFR model was much better than any of the r-squared values returned in the linear regression models, but my accuracy and mean absolute error didn't look that good. Below are the performance metrics for my model:\n",
    "1. R-squared: `0.855`\n",
    "2. Mean absolute error: `10,866`\n",
    "\n",
    "This is a classic example of an overfit model. My regressor trained really well on my training data, but did a bad job predicting the burn size of my test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
